
  完全分布式运行要保证几个虚拟机的节点时间完全一致,这里我们用ntp这个插件来保持一致.基本原理就是会每隔一段时间从远程获取标准时间,来更新本地时间.
  一.安装ntp
       1.安装.
          yum install -y ntp ntpdate
       2.配置从哪里的远程来获取标准时间.
         ntpdate cn.pool.ntp.org
       3.设置开启启动
          hwclock --systohc
       4.设置将时间写入到系统.
          hwclock -w
      用date命令即可查看本地时间.
   二.安装VIM.
        yum install -y vim  (这个个人习惯,用vi也行)



三.完全分布式部署hadoop.
    1.首先对要建的集群进行规划.规划ResourceManager,namenode,SecondaryNameNode在哪个节点上,在一个集群中,这三个只存在于某一个节点即可.
       hadoop116                               hadoop117                                      hadoop118
       NameNode                                ResourceManager                            SecondaryNameNode
       DataNode                                   DataNode                                         DataNode             (每个节点上必须要有,实际存储文件)
       NodeManager                            NodeManager                                  NodeManager      (每个节点上必须要有,实际执行任务)
       
    2.准备三台虚拟机
       要求如下:
         a.安装好jdk和hadoop,并配置好环境变量) .
         b.安装好时间同步软件ntp.
         c.配置好本地hosts文件.(这里最好配置整个集群的ip对应关系)
         d.配置好hadoop的集群.

            在hadoop-env.sh   mapred-env.sh  yarn-env.sh中加上JAVA_HOME

            配置slaves
                  hadoop116
                  hadoop117
                  hadoop118

            配置core-site.xml
                 <!--指定HDFS中的NameNode地址-->
                 <property>
                     <name>fs.defaultFS</name>
                     <value>hdfs://hadoop116:9000</value>
                 </property>
                 <!--指定hadoop运行时产生文件的存储目录-->
                 <property>
                    <name>hadoop.tmp.dir</name>
                    <value>/apps/Hadoop/hadoop/temp</value>
                 </property>
            配置hdfs-site.xml
                 <property>
                    <name>dfs.replication</name> 
                    <value>3</value>
                 </property>
                 <property>
                    <name>dfs.namenode.secondary.http-address</name>
                    <value>hadoop118:50090</value>
                 </property>
  
             配置yarn-site.xml
                   <!--reduce获取数据的方式-->    
                   <property>
                       <name>yarn.nodemanager.aux-services</name>
                       <value>mapreduce_shuffle</value>
                   </property>
                   <!--指定YARN的ResourceManager的地址-->
                  <property>
                       <name>yarn.resourcemanager.hostname</name>
                       <value>hadoop117</value>
                  </property>
 
               配置mapred-site.xml
                    <!--指定mr运行子yarn上-->
                   <property>
                      <name>mapreduce.framework.name</name>
                      <value>yarn</value>
                  </property>
        
        推介配置好一台后,克隆出其他两台.以上三台配置好之后最好在每个虚拟机的hosts文件中配置好三个虚拟机的ip对应关系.
                     
    2.使用SSH免密连接.
       a.SSH介绍:
           一种远程登录会话和其他服务的一种安全的协议,速度快,可以运行在linux,unix等系统上.
           为什么安全:因为发送的消息都是密文,而比如telnet就发送的是明文,相对不安全.
       b.为什么要使用SSH?
           虚拟机要相互通信,必须要使用协议,也就是一种通信标准,而SSH传输速度快(会压缩),又安全(使用密文).
       c.怎么使用:
           两种模式,也就是两种方法.
           第一种级别（基于口令的安全验证）
              只要你知道自己帐号和口令，就可以登录到远程主机。所有传输的数据都会被加密，但是不能保证你正在连接的服务器就是你想连接的服务器。可能会有别的服务器在冒充真正的服务器，
              也就是受到“中间人”这种方式的攻击。
          第二种级别（基于密匙的安全验证）
              需要依靠密匙，也就是你必须为自己创建一对密匙，并把公用密匙放在需要访问的服务器上。如果你要连接到SSH服务器上，客户端软件就会向服务器发出请求，请求用你的密匙进行安全验证。
              服务器收到请求之后，先在该服务器上你的主目录下寻找你的公用密匙，然后把它和你发送过来的公用密匙进行比较。如果两个密匙一致，服务器就用公用密匙加密“质询”（challenge）
              并把它发送给客户端软件。客户端软件收到“质询”之后就可以用你的私人密匙解密再把它发送给服务器。
          一般来说,更推介第二种:
              因为不仅加密所有传送的数据，而且“中间人”这种攻击方式也是不可能的（因为他没有你的私人密匙)
              可以免密码登录.
      d.安装ssh:
         yum install －y openssh-server openssh-clients
              
      前面说了一大堆,就是为了说明这里使用第二种方式:
          使用方法:
             a.生成公钥和密钥
                ssh-keygen -t rsa   (然后连按三下空格)
                执行完这一步后,在root目录下面有个.ssh的文件夹,id_rsa:密匙        id_rsa.pub:公匙.
             b.把公钥放在需要免密登录的机器上.
                ssh-copy-id [用户名]@[hostname或登录ip]

          然后使用 ssh [用户名]@[hostname或登录ip]直接登录即可(第一次需要输入密码)

          也就是每一台虚拟机都要生成公钥和私钥,然后把公钥依次放在要登录的虚拟机上(注意最好也给本虚拟机复制一次公钥,做免密).

      顺便科普一下第一种的使用方式:
              ssh [用户名]@[登录ip]
   3.格式化namenode.(在配置了NameNode的虚拟机上启动即可,这里是hadoop116)
      hdfs namenode -format
   4.启动hdfs.(也是一样在配置了namenode的虚拟机上启动)
      这里是一键启动,可以直接启动一个namenode和三个datanode.当然还有一个SecondNamenode.
      start-dfs.sh   (关闭:stop-yarn.sh)
      想一下它为什么可以一下子启动?知道要启动哪个节点?
           个人想的应该是配置了slaves,然后又可以直接连接,就可以一键启动了.
   到这里如果能成访问192.168.5.116:50070(配置有namenode的节点),说明hdfs就启动成功了,
  
   5.启动yarn(在配置了resourceManager的节点上启动)
      start-yarn.sh
      关闭:stop-yarn.sh
    到这里能访问http://192.168.5.117:8088/cluster即说明yarn启动成功.
   
   6.测试集群.
     上传文件:
         hdfs dfs -mkdir -p /user/hadoop/input/conf
         hdfs dfs -put etc/hadoop/*.xml /user/hadoop/input/conf
     查看文件:
         /apps/Hadoop/hadoop-2.7.6/temp/dfs/data/current/BP-1953468321-192.168.5.116-1572876825370/current/finalized/subdir0/subdir0
         可以看到每个节点都有这些文件.
     也可以执行一下其他命令看一下.比如:
          hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar wordcount /user/hadoop/input/conf /user/hadoop/output
     下载: 
         hdfs fs -get [文件路径]




如果发现datanode一直启动不起来,可能是datanode的clusterID与namenode的ID不一致.
        
                


