


一.Hbase安装配置.
    1.下载Hbase包,在官网下载的.    
        这里用的1.3版本.hbase-1.3.5-bin.tar.gz,移到/apps/soft包下面
    2.解压
       tar -zxvf hbase-1.3.5-bin.tar.gz -C /apps
    3.修改名称
       mv hbase-1.3.5-bin.tar.gz hbase
    4.到conf目录下.
       (1).配置regionservers.
            hadoop116
            hadoop117
            hadoop118
       (2)配置hbase-env.sh
           启动:  export JAVA_HOME=/apps/jdk/jdk1.8.0_171
           禁止:   export HBASE_MASTER_OPTS="$HBASE_MASTER_OPTS -XX:PermSize=128m -XX:MaxPermSize=128m -XX:ReservedCodeCacheSize=256m"
                     export HBASE_REGIONSERVER_OPTS="$HBASE_REGIONSERVER_OPTS -XX:PermSize=128m -XX:MaxPermSize=128m -XX:ReservedCodeCacheSize=256m"
                     禁止的这两个是因为用的jdk1.8,如果1.7以下就不需要禁止.
            export HBASE_MANAGES_ZK=false           #禁用Hbase自带的zk
        (3)配置hbase-site.xml
           <configuration>
               <!--hbase的根目录,将来HBase所有的数据都放在HBase文件夹下-->
              <property>
                 <name>hbase.rootdir</name>
                 <value>hdfs://hadoop116:9000/hbase</value>
             </property>
            <!--是否是集群模式 -->
            <property>
                <name>hbase.cluster.distributed</name>
                <value>true</value>
           </property>
           <!--服务端口 -->
           <property>
               <name>hbase.master.port</name>
               <value>16000</value>
           </property>
           <!--配置zk -->
           <property>
              <name>hbase.zookeeper.quorum</name>
             <value>hadoop116,hadoop117,hadoop118</value>
          </property>
          <!--zk的数据存放的位置 -->
          <property>
             <name>hbase.zookeeper.property.dataDir</name>
             <value>/apps/zookeeper/zookeeper-3.4.14/zkData</value>
         </property>
       </configuration>
     5.在Hbase中的conf目录下,创建hadoop配置文件的软链接.
         ln -s /apps/Hadoop/hadoop/etc/hadoop/core-site.xml  /apps/hbase/conf/core-site.xml
         ln -s /apps/Hadoop/hadoop/etc/hadoop/hdfs-site.xml /apps/hbase/conf/hdfs-site.xml
     6.将以上操作同步在hadoop116,hadoop117,hadoop118.
        这里是直接复制配置好的conf文件夹,到其他两个服务器.通过XShell.
        注意那两个软连接.

二.启动
    1.启动HDFS.
      这里是直接在以前配置的hadoop的基础上启动的.只是改变了每个服务器中hosts文件中的对应关系.其他没有变.因为ip变了.
      在配置了namenode的服务器上开启hdfs,这里是hadoop116.
       start-dfs.sh.   (这个命令在任意目录下都可以直接运行,暂时不清楚原因)
    2.启动zk.
      到达zk的bin目录下:zkServer.sh start,三台都要起.
    3.启动hbase.
       (1)命令介绍.
            hbase:进入hbase的shell命令操作.
            hbase-daemon.sh,hbase-daemon.sh: 单节点开启关闭hbase. 
            start-hbase.sh,stop-hbase.sh:群起和群关.
       (2)测试单机模式.
            1).启动master,在哪台机器上起哪个就是master.这里启动的是118.
                bin/hbase-daemon.sh start master           
                如果这一步启动成功:在浏览器访问:192.168.1.118:16010会出现控制台页面
            2).启动一个regionserver,这里还是在118上启动的.
                bin/hbase-daemon.sh start regionserver
               然后可以看以下控制台有相应的regionserver信息.
       (3)测试群起模式.
            1)刚刚启动了master,regionserver现在先统一关闭.
               bin/stop-hbase.sh                #在master那个机器上关闭.
            2)群起.
               bin/start-hbase.sh                #在哪个机器上起,哪个就是master
         
    
